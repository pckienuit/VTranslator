"""Download and convert Stage 1 models for the hybrid pipeline."""

from __future__ import annotations

import json
import subprocess
import sys
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parent.parent
CONFIG_PATH = REPO_ROOT / "src" / "config" / "settings.json"


def load_config():
    if not CONFIG_PATH.exists():
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file cáº¥u hÃ¬nh táº¡i {CONFIG_PATH}")
        sys.exit(1)

    with open(CONFIG_PATH, "r", encoding="utf-8") as file:
        return json.load(file)


def setup_stage1_model(config):
    print("\n" + "=" * 60)
    print("GIAI ÄOáº N 1: Thiáº¿t láº­p MÃ´ hÃ¬nh Dá»‹ch thuáº­t (CTranslate2)")
    print("=" * 60)

    model_dir = config["stage1_model_dir"]
    hf_name = config["stage1_hf_name"]

    models_dir = REPO_ROOT / "models"
    models_dir.mkdir(exist_ok=True)

    output_dir = REPO_ROOT / model_dir

    if output_dir.exists() and (output_dir / "model.bin").exists():
        print(f"âœ… MÃ´ hÃ¬nh CTranslate2 Ä‘Ã£ tá»“n táº¡i táº¡i: {output_dir}")
        print("   Bá» qua bÆ°á»›c chuyá»ƒn Ä‘á»•i.")
        return True

    print(f"ğŸ“¥ Äang táº£i vÃ  chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh: {hf_name}")
    print(f"   ÄÃ­ch: {output_dir}")
    print("   Cáº¥u hÃ¬nh: LÆ°á»£ng tá»­ hÃ³a INT8 (tá»‘i Æ°u cho VRAM)")
    print("\nâ³ QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt...")

    cmd = [
        "ct2-transformers-converter",
        "--model",
        hf_name,
        "--output_dir",
        str(output_dir),
        "--quantization",
        "int8",
    ]

    try:
        subprocess.run(cmd, check=True, capture_output=True, text=True)
        print("\nâœ… Chuyá»ƒn Ä‘á»•i thÃ nh cÃ´ng!")
        print(f"   MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_dir}")
        return True

    except subprocess.CalledProcessError as exc:
        print("\nâŒ Lá»—i khi chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh:")
        print(f"   {exc.stderr}")
        return False
    except FileNotFoundError:
        print("\nâŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y lá»‡nh 'ct2-transformers-converter'")
        print("   HÃ£y Ä‘áº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t ctranslate2:")
        print("   pip install ctranslate2")
        return False


def setup_stage2_model(config):
    print("\n" + "=" * 60)
    print("GIAI ÄOáº N 2: Thiáº¿t láº­p MÃ´ hÃ¬nh Tinh chá»‰nh (Ollama)")
    print("=" * 60)

    ollama_model = config.get("ollama_model", "llama3.2:3b")

    print(f"ğŸ“‹ PhiÃªn báº£n Ollama sá»­ dá»¥ng mÃ´ hÃ¬nh: {ollama_model}")
    print()
    print("âœ… MÃ´ hÃ¬nh LLM sáº½ Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi Ollama.")
    print("   KhÃ´ng cáº§n táº£i GGUF thá»§ cÃ´ng!")
    print()
    print("ğŸ“ HÆ°á»›ng dáº«n:")
    print("   1. CÃ i Ä‘áº·t Ollama: https://ollama.ai/download")
    print(f"   2. Táº£i mÃ´ hÃ¬nh: ollama pull {ollama_model}")
    print("   3. Khá»Ÿi Ä‘á»™ng Ollama: ollama serve")
    print()
    print("ğŸ’¡ Äá»ƒ Ä‘á»•i mÃ´ hÃ¬nh, chá»‰nh sá»­a 'ollama_model' trong src/config/settings.json")
    print("   Sau Ä‘Ã³ cháº¡y: ollama pull <tÃªn-mÃ´-hÃ¬nh-má»›i>")

    return True


def verify_installation():
    print("\n" + "=" * 60)
    print("KIá»‚M TRA THÃ€NH PHáº¦N")
    print("=" * 60)

    required_packages = {
        "ctranslate2": "ctranslate2",
        "transformers": "transformers",
        "sentencepiece": "sentencepiece",
        "gradio": "gradio",
        "requests": "requests",
    }

    all_installed = True
    for module_name, package_name in required_packages.items():
        try:
            __import__(module_name)
            print(f"âœ… {package_name}")
        except ImportError:
            print(f"âŒ {package_name} - CHÆ¯A CÃ€I Äáº¶T")
            all_installed = False

    if not all_installed:
        print("\nâš ï¸  Má»™t sá»‘ thÆ° viá»‡n chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t.")
        print(
            "   Cháº¡y: pip install ctranslate2 transformers sentencepiece gradio requests torch"
        )
        return False

    return True


def main():
    print("=" * 60)
    print("THIáº¾T Láº¬P PIPELINE Dá»ŠCH THUáº¬T LAI (OLLAMA)")
    print("=" * 60)
    print("Script nÃ y sáº½ táº£i xuá»‘ng vÃ  chuáº©n bá»‹ mÃ´ hÃ¬nh Stage 1.")
    print("MÃ´ hÃ¬nh LLM Stage 2 sáº½ Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi Ollama.")
    print()

    if not verify_installation():
        sys.exit(1)

    config = load_config()
    print("\nâœ… ÄÃ£ Ä‘á»c cáº¥u hÃ¬nh tá»« src/config/settings.json")

    if not setup_stage1_model(config):
        print("\nâŒ Thiáº¿t láº­p Giai Ä‘oáº¡n 1 tháº¥t báº¡i.")
        sys.exit(1)

    setup_stage2_model(config)

    print("\n" + "=" * 60)
    print("âœ… HOÃ€N Táº¤T THIáº¾T Láº¬P STAGE 1")
    print("=" * 60)
    print("MÃ´ hÃ¬nh dá»‹ch thÃ´ Ä‘Ã£ sáºµn sÃ ng!")
    print("\nBÆ°á»›c tiáº¿p theo:")
    print("1. CÃ i Ä‘áº·t Ollama tá»«: https://ollama.ai/download")
    print(f"2. Táº£i mÃ´ hÃ¬nh LLM: ollama pull {config.get('ollama_model', 'llama3.2:3b')}")
    print("3. Cháº¡y á»©ng dá»¥ng: python run_app.py")
    print("\nğŸ’¡ Hoáº·c cháº¡y script tá»± Ä‘á»™ng: scripts/setup_ollama.bat")


if __name__ == "__main__":
    main()
